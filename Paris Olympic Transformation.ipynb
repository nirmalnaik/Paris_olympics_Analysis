{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57732eeb-7795-45c1-af4c-8b17de59455f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, current_date, datediff,upper\n",
    "from pyspark.sql.types import IntegerType, DoubleType, BooleanType, DateType\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae5e134e-719b-4eb6-8bb5-3470c0b4ce54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-3199950410767471>, line 8\u001b[0m\n",
       "\u001b[1;32m      1\u001b[0m configs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.auth.type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOAuth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
       "\u001b[1;32m      2\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth.provider.type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
       "\u001b[1;32m      3\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth2.client.id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m96b06261-0912-4e2b-a387-1becced6d9f2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
       "\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth2.client.secret\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH858Q~V9uL5TjrWlilOOJ2hy-BaGTBJvgAE5acfL\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
       "\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth2.client.endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://login.microsoftonline.com/cfe42d25-5bf2-40ce-aef5-b434684f30ef/oauth2/token\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
       "\u001b[0;32m----> 8\u001b[0m dbutils\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mmount(\n",
       "\u001b[1;32m      9\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabfss://paris-olympic-data@parisolympicdatanirmal.dfs.core.windows.net\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
       "\u001b[1;32m     10\u001b[0m     mount_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/parisolymic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
       "\u001b[1;32m     11\u001b[0m     extra_configs\u001b[38;5;241m=\u001b[39mconfigs\n",
       "\u001b[1;32m     12\u001b[0m )\n",
       "\n",
       "File \u001b[0;32m/databricks/python_shell/dbruntime/dbutils.py:378\u001b[0m, in \u001b[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
       "\u001b[1;32m    376\u001b[0m exc\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[1;32m    377\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
       "\n",
       "\u001b[0;31mExecutionError\u001b[0m: An error occurred while calling o401.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:141)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1126)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1152)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1146)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:702)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1084)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:857)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1073)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:710)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:482)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:482)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:375)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:534)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:638)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:658)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:543)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:535)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:503)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:637)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:637)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:615)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:840)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ExecutionError",
        "evalue": "An error occurred while calling o401.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:141)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1126)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1152)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1146)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:702)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1084)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:857)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1073)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:710)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:482)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:482)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:375)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:534)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:638)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:658)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:543)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:535)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:503)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:637)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:637)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:615)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ExecutionError</span>: An error occurred while calling o401.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:141)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1126)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1152)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1146)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:702)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1084)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:857)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1073)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:710)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:482)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:482)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:375)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:534)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:638)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:658)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:543)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:535)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:503)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:637)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:637)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:615)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)",
        "File \u001b[0;32m<command-3199950410767471>, line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m configs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.auth.type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOAuth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth.provider.type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth2.client.id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m96b06261-0912-4e2b-a387-1becced6d9f2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth2.client.secret\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH858Q~V9uL5TjrWlilOOJ2hy-BaGTBJvgAE5acfL\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfs.azure.account.oauth2.client.endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://login.microsoftonline.com/cfe42d25-5bf2-40ce-aef5-b434684f30ef/oauth2/token\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 8\u001b[0m dbutils\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mmount(\n\u001b[1;32m      9\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabfss://paris-olympic-data@parisolympicdatanirmal.dfs.core.windows.net\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     mount_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/parisolymic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     extra_configs\u001b[38;5;241m=\u001b[39mconfigs\n\u001b[1;32m     12\u001b[0m )\n",
        "File \u001b[0;32m/databricks/python_shell/dbruntime/dbutils.py:378\u001b[0m, in \u001b[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m exc\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
        "\u001b[0;31mExecutionError\u001b[0m: An error occurred while calling o401.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:141)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1126)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1152)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:73)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:73)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:137)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1146)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/parisolymic\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:702)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1084)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:857)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1073)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:710)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:482)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:482)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:375)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:534)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:638)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:658)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:543)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:535)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:503)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:637)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:637)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:615)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "\"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "\"fs.azure.account.oauth2.client.id\": \"\",\n",
    "\"fs.azure.account.oauth2.client.secret\": '',\n",
    "\"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com//oauth2/token\"}\n",
    "\n",
    "\n",
    "dbutils.fs.mount(\n",
    "    source=\"abfss://paris-olympic-data@parisolympicdatanirmal.dfs.core.windows.net\",\n",
    "    mount_point=\"/mnt/parisolymic\",\n",
    "    extra_configs=configs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b664ea93-87cb-497e-9102-83ce73242c8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/parisolymic/raw-data/</td><td>raw-data/</td><td>0</td><td>1724015332000</td></tr><tr><td>dbfs:/mnt/parisolymic/transformed-data/</td><td>transformed-data/</td><td>0</td><td>1724015358000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/parisolymic/raw-data/",
         "raw-data/",
         0,
         1724015332000
        ],
        [
         "dbfs:/mnt/parisolymic/transformed-data/",
         "transformed-data/",
         0,
         1724015358000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%fs\n",
    "ls \"/mnt/parisolymic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3064409b-0627-451c-833b-356375af5cac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2408287311344475#setting/sparkui/0904-201308-tz5tk1yp/driver-4073070804488274973\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8d44399990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c637918-0578-4293-9316-5963588c0a3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "athletes = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/athletes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff69fe8-43a5-49df-bbf9-8dbc2748cc82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------+--------------------+------+--------+------------+--------+------------+-----------+----------------+----------------+------+------+--------------------+--------------------+--------------------+-------------------+-------------+-------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   code|                name|     name_short|             name_tv|gender|function|country_code| country|country_full|nationality|nationality_full|nationality_code|height|weight|         disciplines|              events|          birth_date|        birth_place|birth_country|    residence_place|residence_country|            nickname|             hobbies|          occupation|           education|              family|                lang|               coach|              reason|                hero|           influence|          philosophy|  sporting_relatives|              ritual|        other_sports|\n",
      "+-------+--------------------+---------------+--------------------+------+--------+------------+--------+------------+-----------+----------------+----------------+------+------+--------------------+--------------------+--------------------+-------------------+-------------+-------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1532872|    ALEKSANYAN Artur|   ALEKSANYAN A|    Artur ALEKSANYAN|  Male| Athlete|         ARM| Armenia|     Armenia|    Armenia|         Armenia|             ARM|     0|   0.0|       ['Wrestling']|\"[\"\"Men's Greco-R...|          1991-10-21|             GYUMRI|      Armenia|             GYUMRI|          Armenia|          White Bear|Playing and watch...|             Athlete|Graduated from Sh...|Father, Gevorg Al...|Armenian, English...|Gevorg Aleksanyan...|He followed his f...|Footballer Zinedi...|His father, Gevor...|\"\"\"Wrestling is m...|                NULL|                NULL|                NULL|\n",
      "|1532873|      AMOYAN Malkhas|       AMOYAN M|      Malkhas AMOYAN|  Male| Athlete|         ARM| Armenia|     Armenia|    Armenia|         Armenia|             ARM|     0|   0.0|       ['Wrestling']|\"[\"\"Men's Greco-R...|          1999-01-22|            YEREVAN|      Armenia|            YEREVAN|          Armenia|                NULL|                NULL|                NULL|                NULL|                NULL|            Armenian|                NULL|                NULL|                NULL|                NULL|\"\"\"To become a go...| you first have t...|        6 Oct 2018)\"|Uncle, Roman Amoy...|\n",
      "|1532874|     GALSTYAN Slavik|     GALSTYAN S|     Slavik GALSTYAN|  Male| Athlete|         ARM| Armenia|     Armenia|    Armenia|         Armenia|             ARM|     0|   0.0|       ['Wrestling']|\"[\"\"Men's Greco-R...|          1996-12-21|               NULL|         NULL|            YEREVAN|          Armenia|                NULL|                NULL|                NULL|                NULL|                NULL|            Armenian|Personal: Martin ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "|1532944|   HARUTYUNYAN Arsen|  HARUTYUNYAN A|   Arsen HARUTYUNYAN|  Male| Athlete|         ARM| Armenia|     Armenia|    Armenia|         Armenia|             ARM|     0|   0.0|       ['Wrestling']|\"[\"\"Men's Freesty...|          1999-11-22|              MASIS|      Armenia|            YEREVAN|          Armenia|                NULL|                NULL|             Athlete|Graduated with a ...|Wife, Diana (marr...|            Armenian|National: Habetna...|While doing karat...|Wrestler Armen Na...|                NULL|Nothing is impos...|                NULL|                NULL|                NULL|\n",
      "|1532945|     TEVANYAN Vazgen|     TEVANYAN V|     Vazgen TEVANYAN|  Male| Athlete|         ARM| Armenia|     Armenia|    Armenia|         Armenia|             ARM|     0|   0.0|       ['Wrestling']|\"[\"\"Men's Freesty...|          1999-10-27|          POKR VEDI|      Armenia|               NULL|          Armenia|                NULL|                NULL|             Athlete|Studied at the Ar...|Wife, Sona (marri...|   Armenian, Russian|National: Habetna...|My family did no...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "|1532951|       ARENAS Lorena|       ARENAS L|       Lorena ARENAS|Female| Athlete|         COL|Colombia|    Colombia|   Colombia|        Colombia|             COL|   162|   0.0|       ['Athletics']|\"[\"\"Women's 20km ...| 'Marathon Race W...|         1993-09-17|      PEREIRA|           Colombia|        MELBOURNE|           Australia|                NULL|                NULL|             Athlete|Physical Educatio...|Father, Jose Oton...|             Spanish|Personal: Brent V...|                NULL|Race walker Luis ...|                NULL|                NULL|                NULL|In competition sh...|\n",
      "|1533112|     McKENZIE Ashley|     McKENZIE A|     Ashley McKENZIE|  Male| Athlete|         JAM| Jamaica|     Jamaica|    Jamaica|         Jamaica|             JAM|     0|   0.0|            ['Judo']|      ['Men -60 kg']|          1989-07-17|             LONDON|Great Britain|          CAMBERLEY|    Great Britain|             Bad Boy|               Music|             Athlete|                NULL|One daughter, Lan...|             English|Personal and Nati...|\"\"\"I was thrown o...|       25 Jun 2024)\"|Boxer Muhammad Al...|\"\"\"My coach Luke ...|       25 Jun 2024)\"|                NULL|                NULL|\n",
      "|1533136|BASS BITTAYE Gina...|BASS BITTAYE GM|Gina Mariam BASS ...|Female| Athlete|         GAM|  Gambia|      Gambia|     Gambia|          Gambia|             GAM|   161|   0.0|       ['Athletics']|  \"[\"\"Women's 100m\"\"|  \"\"Women's 200m\"\"]\"|         1995-05-03|     TUBAKUTA|             Gambia|             NULL|                NULL|Earlier in her ca...|                NULL|Athlete, police o...|                NULL|Husband, Mustapha...|     English, French|Personal: Christo...|I started runnin...|\"Sprinter Shelly-...| she is consisten...| 16 Jan 2023)</p>...| three fourth pla...|               2020)|\n",
      "|1533176|     CAMARA Ebrahima|       CAMARA E|     Ebrahima CAMARA|  Male| Athlete|         GAM|  Gambia|      Gambia|     Gambia|          Gambia|             GAM|   178|   0.0|       ['Athletics']|  \"[\"\"Men's 100m\"\"]\"|          1996-09-18|            BUNDUNG|       Gambia|             ANGERS|           France|                NULL|Running, watching...|Athlete, prison o...|                NULL|Married. One daug...|Arabic, English, ...|Personal: Christo...|\"\"\"I love running...|        7 Jul 2024)\"|Sprinter Gina Mar...|Momodou Lamin Kuj...|\"\"\"What does not ...|        7 Jul 2024)\"|                NULL|\n",
      "|1533188| RUEDA SANTOS Lizeth| RUEDA SANTOS L| Lizeth RUEDA SANTOS|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|       ['Triathlon']|\"[\"\"Women's Indiv...|          1994-03-07|        GUADALAJARA|       Mexico|             XALAPA|           Mexico|                NULL|                NULL|             Athlete|Studied Medicine ...|                NULL|             Spanish|Personal: Eugenio...|Was a competitive...|                NULL|                NULL|                NULL|                NULL|                NULL|Competed in marat...|\n",
      "|1533189|TAPIA VIDAL Rosa ...| TAPIA VIDAL RM|Rosa Maria TAPIA ...|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|       ['Triathlon']|\"[\"\"Women's Indiv...|          1997-08-27|         HERMOSILLO|       Mexico|        GUADALAJARA|           Mexico|                NULL|                NULL|             Athlete|Nutrition - Unive...|                NULL|    English, Spanish|Luis Miguel Chve...|She always liked ...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "|1533190|   GRAJALES Crisanto|     GRAJALES C|   Crisanto GRAJALES|  Male| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|       ['Triathlon']|\"[\"\"Men's Individ...|          1987-05-06|             XALAPA|       Mexico|             XALAPA|           Mexico|Diamante Negro (B...|        Music, films|             Athlete|Sport Studies - U...|Father, Crisanto ...|             Spanish|Personal: Eugenio...|\"Both his parents...|       29 Jul 2016)\"|Athlete German Si...|                NULL|\"\"\"In triathlon t...|       29 Jul 2016)\"|                NULL|\n",
      "|1533208|    MAAROUFOU Hachim|    MAAROUFOU H|    Hachim MAAROUFOU|  Male| Athlete|         COM| Comoros|     Comoros|    Comoros|         Comoros|             COM|   183|   0.0|       ['Athletics']|  \"[\"\"Men's 100m\"\"]\"|          1997-02-13|          MARSEILLE|       France|          MARSEILLE|           France|                NULL|                NULL|             Athlete|                NULL|                NULL|              French|Personal: Franck ...|\"Started training...|       17 Jul 2003)\"|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "|1533209|        SAADI Maesha|        SAADI M|        Maesha SAADI|Female| Athlete|         COM| Comoros|     Comoros|    Comoros|         Comoros|             COM|     0|   0.0|        ['Swimming']|\"[\"\"Women's 50m F...|          2007-01-16|             VIENNE|       France|SAINT-ROMAIN-EN-GAL|           France|                NULL|                NULL|    Athlete, student|                NULL|Fther, Abdou-Sala...|              French|Personal: Marc-Ol...|Recruited into th...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "|1533230|      DIOSDADO Nuria|     DIOSDADO N|      Nuria DIOSDADO|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|['Artistic Swimmi...|    ['Team', 'Duet']|          1990-08-22|        GUADALAJARA|       Mexico|        MEXICO CITY|           Mexico|\"Nutria (\"\"Otter\"...|Spending time wit...|Athlete, sport so...|Studied Business ...|Husband, Javier A...|             Spanish|National: Adriana...|\"Began artistic s...|        6 Jan 2020)\"|Spanish artistic ...|         Her parents|\"\"\"Let everything...| no matter how di...|                NULL|\n",
      "|1533231|       JIMENEZ Joana|      JIMENEZ J|       Joana JIMENEZ|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|['Artistic Swimmi...|    ['Team', 'Duet']|          1993-08-19|ECATEPEC DE MORELOS|       Mexico|        MEXICO CITY|           Mexico|                 Joa|             Dancing|Athlete, sport so...|Studied undergrad...|      Brother, Jorge|             Spanish|National: Adriana...|\"Her parents enro...|              Mexico| the first team w...| 'Does that reall...|      at that moment| I wanted to be o...|                NULL|\n",
      "|1533232|     SOBRINO Jessica|      SOBRINO J|     Jessica SOBRINO|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|['Artistic Swimmi...|            ['Team']|          1994-05-26|        MEXICO CITY|       Mexico|        MEXICO CITY|           Mexico|                NULL|Going to the movi...|             Athlete|Studied Business ...|      Sister, Pamela|             Spanish|National: Adriana...|Followed her sist...|                NULL|                NULL|                NULL|\"Uncle, Salvador ...| finished 11th in...|                NULL|\n",
      "|1533234|      ALFEREZ Regina|      ALFEREZ R|      Regina ALFEREZ|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|['Artistic Swimmi...|            ['Team']|          1997-12-01|               NULL|         NULL|        MEXICO CITY|           Mexico|                NULL|Travel, photograp...|             Athlete|Studied at Tecmil...|                NULL|             Spanish|National: Adriana...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "|1533235|   ARELLANO Fernanda|     ARELLANO F|   Fernanda ARELLANO|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|['Artistic Swimmi...|            ['Team']|          2002-02-28|               NULL|         NULL|        MEXICO CITY|           Mexico|                NULL|                NULL|    Athlete, student|Studies at the Un...| Partner, Iker Casas|             Spanish|National: Adriana...|Trained in swimmi...|                NULL|                NULL|                NULL|Partner, Iker Cas...|                NULL|                NULL|\n",
      "|1533237|      TOSCANO Pamela|      TOSCANO P|      Pamela TOSCANO|Female| Athlete|         MEX|  Mexico|      Mexico|     Mexico|          Mexico|             MEX|     0|   0.0|['Artistic Swimmi...|            ['Team']|          2000-01-13|               NULL|         NULL|        GUADALAJARA|           Mexico|                NULL|        Choreography|Athlete, sport so...|Studied Business ...|                NULL|             Spanish|National: Adriana...|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|                NULL|\n",
      "+-------+--------------------+---------------+--------------------+------+--------+------------+--------+------------+-----------+----------------+----------------+------+------+--------------------+--------------------+--------------------+-------------------+-------------+-------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2686b4-3819-4744-ba8f-7e4c26a970a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'code', 'name', 'gender', 'country_code', 'country', 'nationality', \n",
    "    'disciplines', 'events', 'birth_date', 'birth_country', 'coach', 'sporting_relatives'\n",
    "]\n",
    "\n",
    "athletes_df = athletes.select(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9f7863d-210f-4c5b-8737-6b7f448db07c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+------------+--------+-----------+--------------------+--------------------+--------------------+-------------+--------------------+--------------------+\n",
      "|   code|                name|gender|country_code| country|nationality|         disciplines|              events|          birth_date|birth_country|               coach|  sporting_relatives|\n",
      "+-------+--------------------+------+------------+--------+-----------+--------------------+--------------------+--------------------+-------------+--------------------+--------------------+\n",
      "|1532872|    ALEKSANYAN Artur|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Greco-R...|          1991-10-21|      Armenia|Gevorg Aleksanyan...|                NULL|\n",
      "|1532873|      AMOYAN Malkhas|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Greco-R...|          1999-01-22|      Armenia|                NULL| you first have t...|\n",
      "|1532874|     GALSTYAN Slavik|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Greco-R...|          1996-12-21|         NULL|Personal: Martin ...|                NULL|\n",
      "|1532944|   HARUTYUNYAN Arsen|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Freesty...|          1999-11-22|      Armenia|National: Habetna...|                NULL|\n",
      "|1532945|     TEVANYAN Vazgen|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Freesty...|          1999-10-27|      Armenia|National: Habetna...|                NULL|\n",
      "|1532951|       ARENAS Lorena|Female|         COL|Colombia|   Colombia|       ['Athletics']|\"[\"\"Women's 20km ...| 'Marathon Race W...|      PEREIRA|             Spanish|                NULL|\n",
      "|1533112|     McKENZIE Ashley|  Male|         JAM| Jamaica|    Jamaica|            ['Judo']|      ['Men -60 kg']|          1989-07-17|Great Britain|Personal and Nati...|       25 Jun 2024)\"|\n",
      "|1533136|BASS BITTAYE Gina...|Female|         GAM|  Gambia|     Gambia|       ['Athletics']|  \"[\"\"Women's 100m\"\"|  \"\"Women's 200m\"\"]\"|     TUBAKUTA|     English, French| 16 Jan 2023)</p>...|\n",
      "|1533176|     CAMARA Ebrahima|  Male|         GAM|  Gambia|     Gambia|       ['Athletics']|  \"[\"\"Men's 100m\"\"]\"|          1996-09-18|       Gambia|Personal: Christo...|\"\"\"What does not ...|\n",
      "|1533188| RUEDA SANTOS Lizeth|Female|         MEX|  Mexico|     Mexico|       ['Triathlon']|\"[\"\"Women's Indiv...|          1994-03-07|       Mexico|Personal: Eugenio...|                NULL|\n",
      "|1533189|TAPIA VIDAL Rosa ...|Female|         MEX|  Mexico|     Mexico|       ['Triathlon']|\"[\"\"Women's Indiv...|          1997-08-27|       Mexico|Luis Miguel Chve...|                NULL|\n",
      "|1533190|   GRAJALES Crisanto|  Male|         MEX|  Mexico|     Mexico|       ['Triathlon']|\"[\"\"Men's Individ...|          1987-05-06|       Mexico|Personal: Eugenio...|\"\"\"In triathlon t...|\n",
      "|1533208|    MAAROUFOU Hachim|  Male|         COM| Comoros|    Comoros|       ['Athletics']|  \"[\"\"Men's 100m\"\"]\"|          1997-02-13|       France|Personal: Franck ...|                NULL|\n",
      "|1533209|        SAADI Maesha|Female|         COM| Comoros|    Comoros|        ['Swimming']|\"[\"\"Women's 50m F...|          2007-01-16|       France|Personal: Marc-Ol...|                NULL|\n",
      "|1533230|      DIOSDADO Nuria|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|    ['Team', 'Duet']|          1990-08-22|       Mexico|National: Adriana...|\"\"\"Let everything...|\n",
      "|1533231|       JIMENEZ Joana|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|    ['Team', 'Duet']|          1993-08-19|       Mexico|National: Adriana...|      at that moment|\n",
      "|1533232|     SOBRINO Jessica|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|          1994-05-26|       Mexico|National: Adriana...|\"Uncle, Salvador ...|\n",
      "|1533234|      ALFEREZ Regina|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|          1997-12-01|         NULL|National: Adriana...|                NULL|\n",
      "|1533235|   ARELLANO Fernanda|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|          2002-02-28|         NULL|National: Adriana...|Partner, Iker Cas...|\n",
      "|1533237|      TOSCANO Pamela|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|          2000-01-13|         NULL|National: Adriana...|                NULL|\n",
      "+-------+--------------------+------+------------+--------+-----------+--------------------+--------------------+--------------------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "747cd81c-5136-40bf-a85d-77a23e00ae34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert birth_date to date format\n",
    "athletes_df = athletes_df.withColumn(\"birth_date\", col(\"birth_date\").cast(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30a065d8-3013-47ef-b5b4-af1f182a5f4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate age of athletes\n",
    "athletes_df = athletes_df.withColumn(\"age\", datediff(current_date(), col(\"birth_date\")) / 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f64c33d-26ab-4be1-ad2b-234bd2bd70f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Standardize country codes and nationality\n",
    "athletes_df = athletes_df.withColumn(\"country_code\", upper(col(\"country_code\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fe03989-8296-4877-9632-9d7071a16722",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_index\")\n",
    "athletes_df = indexer.fit(athletes_df).transform(athletes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b83cdcb6-28d6-42ee-87e6-be944b204031",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+------------+--------+-----------+--------------------+--------------------+----------+-------------+--------------------+--------------------+------------------+------------+\n",
      "|   code|                name|gender|country_code| country|nationality|         disciplines|              events|birth_date|birth_country|               coach|  sporting_relatives|               age|gender_index|\n",
      "+-------+--------------------+------+------------+--------+-----------+--------------------+--------------------+----------+-------------+--------------------+--------------------+------------------+------------+\n",
      "|1532872|    ALEKSANYAN Artur|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Greco-R...|1991-10-21|      Armenia|Gevorg Aleksanyan...|                NULL|  32.9041095890411|         0.0|\n",
      "|1532873|      AMOYAN Malkhas|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Greco-R...|1999-01-22|      Armenia|                NULL| you first have t...|25.643835616438356|         0.0|\n",
      "|1532874|     GALSTYAN Slavik|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Greco-R...|1996-12-21|         NULL|Personal: Martin ...|                NULL|27.731506849315068|         0.0|\n",
      "|1532944|   HARUTYUNYAN Arsen|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Freesty...|1999-11-22|      Armenia|National: Habetna...|                NULL| 24.81095890410959|         0.0|\n",
      "|1532945|     TEVANYAN Vazgen|  Male|         ARM| Armenia|    Armenia|       ['Wrestling']|\"[\"\"Men's Freesty...|1999-10-27|      Armenia|National: Habetna...|                NULL|24.882191780821916|         0.0|\n",
      "|1532951|       ARENAS Lorena|Female|         COL|Colombia|   Colombia|       ['Athletics']|\"[\"\"Women's 20km ...|      NULL|      PEREIRA|             Spanish|                NULL|              NULL|         1.0|\n",
      "|1533112|     McKENZIE Ashley|  Male|         JAM| Jamaica|    Jamaica|            ['Judo']|      ['Men -60 kg']|1989-07-17|Great Britain|Personal and Nati...|       25 Jun 2024)\"| 35.16712328767123|         0.0|\n",
      "|1533136|BASS BITTAYE Gina...|Female|         GAM|  Gambia|     Gambia|       ['Athletics']|  \"[\"\"Women's 100m\"\"|      NULL|     TUBAKUTA|     English, French| 16 Jan 2023)</p>...|              NULL|         1.0|\n",
      "|1533176|     CAMARA Ebrahima|  Male|         GAM|  Gambia|     Gambia|       ['Athletics']|  \"[\"\"Men's 100m\"\"]\"|1996-09-18|       Gambia|Personal: Christo...|\"\"\"What does not ...| 27.98904109589041|         0.0|\n",
      "|1533188| RUEDA SANTOS Lizeth|Female|         MEX|  Mexico|     Mexico|       ['Triathlon']|\"[\"\"Women's Indiv...|1994-03-07|       Mexico|Personal: Eugenio...|                NULL|30.526027397260275|         1.0|\n",
      "|1533189|TAPIA VIDAL Rosa ...|Female|         MEX|  Mexico|     Mexico|       ['Triathlon']|\"[\"\"Women's Indiv...|1997-08-27|       Mexico|Luis Miguel Chve...|                NULL| 27.04931506849315|         1.0|\n",
      "|1533190|   GRAJALES Crisanto|  Male|         MEX|  Mexico|     Mexico|       ['Triathlon']|\"[\"\"Men's Individ...|1987-05-06|       Mexico|Personal: Eugenio...|\"\"\"In triathlon t...|37.367123287671234|         0.0|\n",
      "|1533208|    MAAROUFOU Hachim|  Male|         COM| Comoros|    Comoros|       ['Athletics']|  \"[\"\"Men's 100m\"\"]\"|1997-02-13|       France|Personal: Franck ...|                NULL|27.583561643835615|         0.0|\n",
      "|1533209|        SAADI Maesha|Female|         COM| Comoros|    Comoros|        ['Swimming']|\"[\"\"Women's 50m F...|2007-01-16|       France|Personal: Marc-Ol...|                NULL|17.654794520547945|         1.0|\n",
      "|1533230|      DIOSDADO Nuria|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|    ['Team', 'Duet']|1990-08-22|       Mexico|National: Adriana...|\"\"\"Let everything...| 34.06849315068493|         1.0|\n",
      "|1533231|       JIMENEZ Joana|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|    ['Team', 'Duet']|1993-08-19|       Mexico|National: Adriana...|      at that moment|31.073972602739726|         1.0|\n",
      "|1533232|     SOBRINO Jessica|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|1994-05-26|       Mexico|National: Adriana...|\"Uncle, Salvador ...|30.306849315068494|         1.0|\n",
      "|1533234|      ALFEREZ Regina|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|1997-12-01|         NULL|National: Adriana...|                NULL|26.786301369863015|         1.0|\n",
      "|1533235|   ARELLANO Fernanda|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|2002-02-28|         NULL|National: Adriana...|Partner, Iker Cas...| 22.53972602739726|         1.0|\n",
      "|1533237|      TOSCANO Pamela|Female|         MEX|  Mexico|     Mexico|['Artistic Swimmi...|            ['Team']|2000-01-13|         NULL|National: Adriana...|                NULL| 24.66849315068493|         1.0|\n",
      "+-------+--------------------+------+------------+--------+-----------+--------------------+--------------------+----------+-------------+--------------------+--------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b637fc1-3d14-443b-813b-af52f0d81609",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coaches = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/coaches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95f5e7a-96f1-48a7-82d4-380702149974",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+---------------+--------+------------+---------+--------------------+-------------------+------+\n",
      "|   code|                name|gender|       function|category|country_code|  country|        country_full|        disciplines|events|\n",
      "+-------+--------------------+------+---------------+--------+------------+---------+--------------------+-------------------+------+\n",
      "|1533246|      PEDRERO Ofelia|Female|          Coach|       C|         MEX|   Mexico|              Mexico|  Artistic Swimming|  Team|\n",
      "|1535775|    RADHI SHENAISHIL|  Male|     Head Coach|       C|         IRQ|     Iraq|                Iraq|           Football|   Men|\n",
      "|1536055| AFLAKIKHAMSEH Majid|  Male|          Coach|       C|         IRI|  IR Iran|Islamic Republic ...|          Taekwondo|  NULL|\n",
      "|1536059|     YOUSEFY Mehrdad|  Male|          Coach|       C|         IRI|  IR Iran|Islamic Republic ...|          Taekwondo|  NULL|\n",
      "|1536060|        MADDAH Minoo|Female|          Coach|       C|         IRI|  IR Iran|Islamic Republic ...|          Taekwondo|  NULL|\n",
      "|1536328|      LOFTUS Adriana|Female|          Coach|       C|         MEX|   Mexico|              Mexico|  Artistic Swimming|  Team|\n",
      "|1538313|    FERRARA Fernando|  Male|     Head Coach|       C|         ARG|Argentina|           Argentina|             Hockey|  NULL|\n",
      "|1538315|     GULLA Alejandra|Female|Assistant Coach|       C|         ARG|Argentina|           Argentina|             Hockey| Women|\n",
      "|1538317|    CAPURRO Santiago|  Male|Assistant Coach|       C|         ARG|Argentina|           Argentina|             Hockey|  NULL|\n",
      "|1538745|     RONCONI Mariano|  Male|     Head Coach|       C|         ARG|Argentina|           Argentina|             Hockey|  NULL|\n",
      "|1538748|     PAULON Ezequiel|  Male|Assistant Coach|       C|         ARG|Argentina|           Argentina|             Hockey|  NULL|\n",
      "|1538751|         VILA Matias|  Male|Assistant Coach|       C|         ARG|Argentina|           Argentina|             Hockey|  NULL|\n",
      "|1539598|KHEIRKHAH HAJIRAS...|  Male|          Coach|       C|         IRI|  IR Iran|Islamic Republic ...|Artistic Gymnastics|  NULL|\n",
      "|1540258|    DAVIS DIAZ David|  Male|          Coach|       C|         MEX|   Mexico|              Mexico|          Taekwondo|  NULL|\n",
      "|1540259|   MENDOZA MORA Abel|  Male|          Coach|       C|         MEX|   Mexico|              Mexico|          Taekwondo|  NULL|\n",
      "|1540260|VICTORIA ESPINOSA...|  Male|          Coach|       C|         MEX|   Mexico|              Mexico|          Taekwondo|  NULL|\n",
      "|1540522|    MILANO Guillermo|  Male|     Head Coach|       C|         ARG|Argentina|           Argentina|           Handball|   Men|\n",
      "|1540638| GOMEZ CORA Santiago|  Male|     Head Coach|       C|         ARG|Argentina|           Argentina|       Rugby Sevens|   Men|\n",
      "|1540639|    GRAVANO Leonardo|  Male|Assistant Coach|       C|         ARG|Argentina|           Argentina|       Rugby Sevens|   Men|\n",
      "|1540840|FILIORIANU Ana Luiza|Female|          Coach|       C|         ROU|  Romania|             Romania|Rhythmic Gymnastics|  NULL|\n",
      "+-------+--------------------+------+---------------+--------+------------+---------+--------------------+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coaches.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c804e672-7c78-428d-85f9-5fe4fbb8873c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+---------------+------------+-------------+-------------+-----------------+------+\n",
      "|   code|                name|gender|       function|country_code|      country| country_full|      disciplines|events|\n",
      "+-------+--------------------+------+---------------+------------+-------------+-------------+-----------------+------+\n",
      "|1533246|      PEDRERO Ofelia|Female|          Coach|         MEX|       Mexico|       Mexico|Artistic Swimming|  Team|\n",
      "|1535775|    RADHI SHENAISHIL|  Male|     Head Coach|         IRQ|         Iraq|         Iraq|         Football|   Men|\n",
      "|1536328|      LOFTUS Adriana|Female|          Coach|         MEX|       Mexico|       Mexico|Artistic Swimming|  Team|\n",
      "|1538315|     GULLA Alejandra|Female|Assistant Coach|         ARG|    Argentina|    Argentina|           Hockey| Women|\n",
      "|1540522|    MILANO Guillermo|  Male|     Head Coach|         ARG|    Argentina|    Argentina|         Handball|   Men|\n",
      "|1540638| GOMEZ CORA Santiago|  Male|     Head Coach|         ARG|    Argentina|    Argentina|     Rugby Sevens|   Men|\n",
      "|1540639|    GRAVANO Leonardo|  Male|Assistant Coach|         ARG|    Argentina|    Argentina|     Rugby Sevens|   Men|\n",
      "|1544157|        THORPE Karen|Female|          Coach|         GBR|Great Britain|Great Britain|Artistic Swimming|  Duet|\n",
      "|1544158|    TOMOMATSU Yumiko|Female|          Coach|         GBR|Great Britain|Great Britain|Artistic Swimming|  Duet|\n",
      "|1544489|      CURRAN Orlaith|Female|Assistant Coach|         IRL|      Ireland|      Ireland|     Rugby Sevens| Women|\n",
      "|1550038|        ARILL Samuel|  Male|Assistant Coach|         PUR|  Puerto Rico|  Puerto Rico|       Basketball| Women|\n",
      "|1550039|MORALES OTERO Carlos|  Male|Assistant Coach|         PUR|  Puerto Rico|  Puerto Rico|       Basketball| Women|\n",
      "|1550047|     BATISTA Gerardo|  Male|          Coach|         PUR|  Puerto Rico|  Puerto Rico|       Basketball| Women|\n",
      "|1555115|     FLANNERY Eimear|Female|Assistant Coach|         IRL|      Ireland|      Ireland|     Rugby Sevens|   Men|\n",
      "|1556249|        DEACU George|  Male|Assistant Coach|         ROU|      Romania|      Romania|       Water Polo|   Men|\n",
      "|1556255|         RATH Bogdan|  Male|     Head Coach|         ROU|      Romania|      Romania|       Water Polo|   Men|\n",
      "|1559048|      WIBERG Johanna|Female|Assistant Coach|         SWE|       Sweden|       Sweden|         Handball| Women|\n",
      "|1559066|     FORSBERG Thomas|  Male|Assistant Coach|         SWE|       Sweden|       Sweden|         Handball| Women|\n",
      "|1559067|         AXNER Tomas|  Male|     Head Coach|         SWE|       Sweden|       Sweden|         Handball| Women|\n",
      "|1561282|  da ROCHA Cristiano|  Male|     Head Coach|         BRA|       Brazil|       Brazil|         Handball| Women|\n",
      "+-------+--------------------+------+---------------+------------+-------------+-------------+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the list of columns to keep\n",
    "columns_to_keep = [\n",
    "    'code', 'name', 'gender', 'function', 'country_code', 'country', \n",
    "    'country_full', 'disciplines', 'events'\n",
    "]\n",
    "\n",
    "# Select only the relevant columns\n",
    "coaches_df = coaches.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in critical fields\n",
    "coaches_df = coaches_df.dropna(subset=['name', 'country', 'disciplines', 'events'])\n",
    "\n",
    "# Standardize the country_code (convert to uppercase)\n",
    "from pyspark.sql.functions import upper, col\n",
    "coaches_df = coaches_df.withColumn(\"country_code\", upper(col(\"country_code\")))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "coaches_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3d0ad4-b732-42bb-aa05-795e68d0f9bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ea35559-9ff9-4ce7-b841-b59f2525479f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+\n",
      "|               event|              sport|sport_code|\n",
      "+--------------------+-------------------+----------+\n",
      "|    MEN'S INDIVIDUAL|            ARCHERY|       ARC|\n",
      "|  WOMEN'S INDIVIDUAL|            ARCHERY|       ARC|\n",
      "|          MEN'S TEAM|            ARCHERY|       ARC|\n",
      "|        WOMEN'S TEAM|            ARCHERY|       ARC|\n",
      "|          MIXED TEAM|            ARCHERY|       ARC|\n",
      "|    MEN'S ALL-AROUND|ARTISTIC GYMNASTICS|       GAR|\n",
      "|MEN'S FLOOR EXERCISE|ARTISTIC GYMNASTICS|       GAR|\n",
      "|  MEN'S POMMEL HORSE|ARTISTIC GYMNASTICS|       GAR|\n",
      "|         MEN'S RINGS|ARTISTIC GYMNASTICS|       GAR|\n",
      "|         MEN'S VAULT|ARTISTIC GYMNASTICS|       GAR|\n",
      "| MEN'S PARALLEL BARS|ARTISTIC GYMNASTICS|       GAR|\n",
      "|MEN'S HORIZONTAL BAR|ARTISTIC GYMNASTICS|       GAR|\n",
      "|          MEN'S TEAM|ARTISTIC GYMNASTICS|       GAR|\n",
      "|  WOMEN'S ALL-AROUND|ARTISTIC GYMNASTICS|       GAR|\n",
      "|       WOMEN'S VAULT|ARTISTIC GYMNASTICS|       GAR|\n",
      "| WOMEN'S UNEVEN BARS|ARTISTIC GYMNASTICS|       GAR|\n",
      "|WOMEN'S BALANCE BEAM|ARTISTIC GYMNASTICS|       GAR|\n",
      "|WOMEN'S FLOOR EXE...|ARTISTIC GYMNASTICS|       GAR|\n",
      "|        WOMEN'S TEAM|ARTISTIC GYMNASTICS|       GAR|\n",
      "|                DUET|  ARTISTIC SWIMMING|       SWA|\n",
      "+--------------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the list of columns to keep\n",
    "columns_to_keep = ['event', 'sport', 'sport_code']\n",
    "\n",
    "# Select only the relevant columns\n",
    "events_df = events.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in critical fields\n",
    "events_df = events_df.dropna(subset=['event', 'sport', 'sport_code'])\n",
    "\n",
    "# Standardize event and sport names (e.g., trimming and converting to uppercase)\n",
    "from pyspark.sql.functions import trim, upper\n",
    "\n",
    "events_df = events_df.withColumn(\"event\", upper(trim(col(\"event\"))))\n",
    "events_df = events_df.withColumn(\"sport\", upper(trim(col(\"sport\"))))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "events_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc41deb-05d6-4293-b8f7-21e2135342f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "medallists = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/medallists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72486a5c-70fd-439b-b937-c7e7a0015adb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------------------+------+----------------+------------+----------------+----+------------+--------------------+----------+----------+-------+\n",
      "|medal_date|  medal_type|medal_code|                name|gender|         country|country_code|     nationality|team|  discipline|               event|event_type|birth_date|   code|\n",
      "+----------+------------+----------+--------------------+------+----------------+------------+----------------+----+------------+--------------------+----------+----------+-------+\n",
      "|2024-07-27|  GOLD MEDAL|       1.0|     EVENEPOEL Remco|  Male|         Belgium|         BEL|         Belgium|NULL|Cycling Road|Men's Individual ...|       ATH|2000-01-25|1903136|\n",
      "|2024-07-27|SILVER MEDAL|       2.0|       GANNA Filippo|  Male|           Italy|         ITA|           Italy|NULL|Cycling Road|Men's Individual ...|       ATH|1996-07-25|1923520|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|       van AERT Wout|  Male|         Belgium|         BEL|         Belgium|NULL|Cycling Road|Men's Individual ...|       ATH|1994-09-15|1903147|\n",
      "|2024-07-27|  GOLD MEDAL|       1.0|         BROWN Grace|Female|       Australia|         AUS|       Australia|NULL|Cycling Road|Women's Individua...|       ATH|1992-07-07|1940173|\n",
      "|2024-07-27|SILVER MEDAL|       2.0|      HENDERSON Anna|Female|   Great Britain|         GBR|   Great Britain|NULL|Cycling Road|Women's Individua...|       ATH|1998-11-14|1912525|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|        DYGERT Chloe|Female|   United States|         USA|   United States|NULL|Cycling Road|Women's Individua...|       ATH|1997-01-01|1955079|\n",
      "|2024-07-27|  GOLD MEDAL|       1.0|           OH Sanguk|  Male|           Korea|         KOR|           Korea|NULL|     Fencing|Men's Sabre Indiv...|      HATH|1996-09-30|1927149|\n",
      "|2024-07-27|SILVER MEDAL|       2.0|       FERJANI Fares|  Male|         Tunisia|         TUN|         Tunisia|NULL|     Fencing|Men's Sabre Indiv...|      HATH|1997-07-22|1937783|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|        SAMELE Luigi|  Male|           Italy|         ITA|           Italy|NULL|     Fencing|Men's Sabre Indiv...|      HATH|1987-07-25|1924595|\n",
      "|2024-07-27|  GOLD MEDAL|       1.0| KONG Man Wai Vivian|Female|Hong Kong, China|         HKG|Hong Kong, China|NULL|     Fencing|Women's pe Indi...|      HATH|1994-02-08|1963262|\n",
      "|2024-07-27|SILVER MEDAL|       2.0|MALLO-BRETON Auriane|Female|          France|         FRA|          France|NULL|     Fencing|Women's pe Indi...|      HATH|1993-10-11|1916183|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|       MUHARI Eszter|Female|         Hungary|         HUN|         Hungary|NULL|     Fencing|Women's pe Indi...|      HATH|2002-09-30|1946375|\n",
      "|2024-07-27|  GOLD MEDAL|       1.0|       SMETOV Yeldos|  Male|      Kazakhstan|         KAZ|      Kazakhstan|NULL|        Judo|          Men -60 kg|      HATH|1992-09-09|1935408|\n",
      "|2024-07-27|SILVER MEDAL|       2.0|       MKHEIDZE Luka|  Male|          France|         FRA|          France|NULL|        Judo|          Men -60 kg|      HATH|1996-01-05|1891304|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|      NAGAYAMA Ryuju|  Male|           Japan|         JPN|           Japan|NULL|        Judo|          Men -60 kg|      HATH|1996-04-15|1896752|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|  GARRIGOS Francisco|  Male|           Spain|         ESP|           Spain|NULL|        Judo|          Men -60 kg|      HATH|1994-12-09|1563544|\n",
      "|2024-07-27|  GOLD MEDAL|       1.0|     TSUNODA Natsumi|Female|           Japan|         JPN|           Japan|NULL|        Judo|        Women -48 kg|      HATH|1992-08-06|1896735|\n",
      "|2024-07-27|SILVER MEDAL|       2.0|BAVUUDORJ Baasankhuu|Female|        Mongolia|         MGL|        Mongolia|NULL|        Judo|        Women -48 kg|      HATH|1999-11-26|1914467|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|      BOUKLI Shirine|Female|          France|         FRA|          France|NULL|        Judo|        Women -48 kg|      HATH|1999-01-24|1891280|\n",
      "|2024-07-27|BRONZE MEDAL|       3.0|      BABULFATH Tara|Female|          Sweden|         SWE|          Sweden|NULL|        Judo|        Women -48 kg|      HATH|2006-01-03|1571911|\n",
      "+----------+------------+----------+--------------------+------+----------------+------------+----------------+----+------------+--------------------+----------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the list of columns to keep\n",
    "columns_to_keep = [\n",
    "    'medal_date', 'medal_type', 'medal_code', 'name', 'gender', 'country', 'country_code', \n",
    "    'nationality', 'team', 'discipline', 'event', 'event_type', 'birth_date', 'code'\n",
    "]\n",
    "\n",
    "# Select only the relevant columns\n",
    "medallists_df = medallists.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in critical fields\n",
    "medallists_df = medallists_df.dropna(subset=['medal_type', 'name', 'country', 'event', 'discipline'])\n",
    "\n",
    "# Standardize medal_type and country_code\n",
    "\n",
    "medallists_df = medallists_df.withColumn(\"medal_type\", upper(trim(col(\"medal_type\"))))\n",
    "medallists_df = medallists_df.withColumn(\"country_code\", upper(trim(col(\"country_code\"))))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "medallists_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8bdbfdb-e402-4650-b345-70e1c04575ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "medals = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/medals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c01393a4-e373-4c92-b0c2-c2056ad4e8ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+--------------------+------------+------+------------+--------------------+----------+-----------------+\n",
      "|  medal_type|medal_code|medal_date|                name|country_code|gender|  discipline|               event|event_type|             code|\n",
      "+------------+----------+----------+--------------------+------------+------+------------+--------------------+----------+-----------------+\n",
      "|  GOLD MEDAL|       1.0|2024-07-27|     Remco EVENEPOEL|         BEL|     M|Cycling Road|Men's Individual ...|       ATH|          1903136|\n",
      "|SILVER MEDAL|       2.0|2024-07-27|       Filippo GANNA|         ITA|     M|Cycling Road|Men's Individual ...|       ATH|          1923520|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|       Wout van AERT|         BEL|     M|Cycling Road|Men's Individual ...|       ATH|          1903147|\n",
      "|  GOLD MEDAL|       1.0|2024-07-27|         Grace BROWN|         AUS|     W|Cycling Road|Women's Individua...|       ATH|          1940173|\n",
      "|SILVER MEDAL|       2.0|2024-07-27|      Anna HENDERSON|         GBR|     W|Cycling Road|Women's Individua...|       ATH|          1912525|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|        Chloe DYGERT|         USA|     W|Cycling Road|Women's Individua...|       ATH|          1955079|\n",
      "|  GOLD MEDAL|       1.0|2024-07-27|               China|         CHN|     W|      Diving|Women's Synchroni...|      TEAM|DIVW3MTEAM2-CHN01|\n",
      "|SILVER MEDAL|       2.0|2024-07-27|       United States|         USA|     W|      Diving|Women's Synchroni...|      TEAM|DIVW3MTEAM2-USA01|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|       Great Britain|         GBR|     W|      Diving|Women's Synchroni...|      TEAM|DIVW3MTEAM2-GBR01|\n",
      "|  GOLD MEDAL|       1.0|2024-07-27|           OH Sanguk|         KOR|     M|     Fencing|Men's Sabre Indiv...|      HATH|          1927149|\n",
      "|SILVER MEDAL|       2.0|2024-07-27|       Fares FERJANI|         TUN|     M|     Fencing|Men's Sabre Indiv...|      HATH|          1937783|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|        Luigi SAMELE|         ITA|     M|     Fencing|Men's Sabre Indiv...|      HATH|          1924595|\n",
      "|  GOLD MEDAL|       1.0|2024-07-27| KONG Man Wai Vivian|         HKG|     W|     Fencing|Women's pe Indi...|      HATH|          1963262|\n",
      "|SILVER MEDAL|       2.0|2024-07-27|Auriane MALLO-BRETON|         FRA|     W|     Fencing|Women's pe Indi...|      HATH|          1916183|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|       Eszter MUHARI|         HUN|     W|     Fencing|Women's pe Indi...|      HATH|          1946375|\n",
      "|  GOLD MEDAL|       1.0|2024-07-27|       Yeldos SMETOV|         KAZ|     M|        Judo|          Men -60 kg|      HATH|          1935408|\n",
      "|SILVER MEDAL|       2.0|2024-07-27|       Luka MKHEIDZE|         FRA|     M|        Judo|          Men -60 kg|      HATH|          1891304|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|      NAGAYAMA Ryuju|         JPN|     M|        Judo|          Men -60 kg|      HATH|          1896752|\n",
      "|BRONZE MEDAL|       3.0|2024-07-27|  Francisco GARRIGOS|         ESP|     M|        Judo|          Men -60 kg|      HATH|          1563544|\n",
      "|  GOLD MEDAL|       1.0|2024-07-27|     TSUNODA Natsumi|         JPN|     W|        Judo|        Women -48 kg|      HATH|          1896735|\n",
      "+------------+----------+----------+--------------------+------------+------+------------+--------------------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the list of columns to keep\n",
    "columns_to_keep = [\n",
    "    'medal_type', 'medal_code', 'medal_date', 'name', 'country_code', \n",
    "    'gender', 'discipline', 'event', 'event_type', 'code'\n",
    "]\n",
    "\n",
    "# Select only the relevant columns\n",
    "medals_df = medals.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in critical fields\n",
    "medals_df = medals_df.dropna(subset=['medal_type', 'name', 'country_code', 'discipline'])\n",
    "\n",
    "# Standardize medal_type and country_code (convert to uppercase)\n",
    "from pyspark.sql.functions import upper, trim\n",
    "\n",
    "medals_df = medals_df.withColumn(\"medal_type\", upper(trim(col(\"medal_type\"))))\n",
    "medals_df = medals_df.withColumn(\"country_code\", upper(trim(col(\"country_code\"))))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "medals_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d37f157-8666-4a9b-bbbc-d5acc55cdd65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "medals_total = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/medals_total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717aa7a1-c174-42b7-89ec-581c1772e1eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+------------+-----+\n",
      "|country_code|Gold Medal|Silver Medal|Bronze Medal|Total|\n",
      "+------------+----------+------------+------------+-----+\n",
      "|         USA|        40|          44|          42|  126|\n",
      "|         CHN|        40|          27|          24|   91|\n",
      "|         JPN|        20|          12|          13|   45|\n",
      "|         AUS|        18|          19|          16|   53|\n",
      "|         FRA|        16|          26|          22|   64|\n",
      "|         NED|        15|           7|          12|   34|\n",
      "|         GBR|        14|          22|          29|   65|\n",
      "|         KOR|        13|           9|          10|   32|\n",
      "|         ITA|        12|          13|          15|   40|\n",
      "|         GER|        12|          13|           8|   33|\n",
      "|         NZL|        10|           7|           3|   20|\n",
      "|         CAN|         9|           7|          11|   27|\n",
      "|         UZB|         8|           2|           3|   13|\n",
      "|         HUN|         6|           7|           6|   19|\n",
      "|         ESP|         5|           4|           9|   18|\n",
      "|         SWE|         4|           4|           3|   11|\n",
      "|         KEN|         4|           2|           5|   11|\n",
      "|         NOR|         4|           1|           3|    8|\n",
      "|         IRL|         4|           0|           3|    7|\n",
      "|         BRA|         3|           7|          10|   20|\n",
      "+------------+----------+------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep (in this case, all are needed)\n",
    "columns_to_keep = ['country_code', 'Gold Medal', 'Silver Medal', 'Bronze Medal', 'Total']\n",
    "\n",
    "# Select the relevant columns\n",
    "medals_total_df = medals_total.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in important columns\n",
    "medals_total_df = medals_total_df.dropna(subset=['country_code', 'Gold Medal', 'Silver Medal', 'Bronze Medal', 'Total'])\n",
    "\n",
    "# Standardize country_code (convert to uppercase)\n",
    "from pyspark.sql.functions import upper, trim\n",
    "\n",
    "medals_total_df = medals_total_df.withColumn(\"country_code\", upper(trim(col(\"country_code\"))))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "medals_total_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27aea821-5a78-421e-9c14-71aaa55d73c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schedules = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/schedules.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d084871-b907-413b-b9b5-82657e6f1bae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+--------+------------+---------------+-----+-----------+-------------+------+----------+--------------------+----------+\n",
      "|start_date|  end_date|       day|  status|  discipline|discipline_code|event|event_medal|        phase|gender|event_type|               venue|venue_code|\n",
      "+----------+----------+----------+--------+------------+---------------+-----+-----------+-------------+------+----------+--------------------+----------+\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group B|     M|     HTEAM|Geoffroy-Guichard...|       STE|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group C|     M|     HTEAM|    Parc des Princes|       PDP|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool B|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool B|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool C|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group A|     M|     HTEAM|        Nice Stadium|       NIC|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group C|     M|     HTEAM|La Beaujoire Stadium|       NAN|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool C|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool A|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool A|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group B|     M|     HTEAM|        Lyon Stadium|       LYO|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group D|     M|     HTEAM|    Bordeaux Stadium|       BOR|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool B|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool B|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool C|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool C|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group A|     M|     HTEAM|   Marseille Stadium|       MRS|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|    FOOTBALL|            FBL|  Men|          0|Men's Group D|     M|     HTEAM|    Parc des Princes|       PDP|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool A|     M|     HTEAM|     Stade de France|       STA|\n",
      "|2024-07-24|2024-07-24|2024-07-24|FINISHED|RUGBY SEVENS|            RU7|  Men|          0| Men's Pool A|     M|     HTEAM|     Stade de France|       STA|\n",
      "+----------+----------+----------+--------+------------+---------------+-----+-----------+-------------+------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    'start_date', 'end_date', 'day', 'status', 'discipline', 'discipline_code', \n",
    "    'event', 'event_medal', 'phase', 'gender', 'event_type', 'venue', 'venue_code'\n",
    "]\n",
    "\n",
    "# Select the relevant columns\n",
    "schedules_df = schedules.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in critical fields\n",
    "schedules_df = schedules_df.dropna(subset=['start_date', 'end_date', 'event', 'discipline'])\n",
    "\n",
    "# Convert start_date and end_date to date format\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "schedules_df = schedules_df.withColumn(\"start_date\", to_date(col(\"start_date\"), 'yyyy-MM-dd'))\n",
    "schedules_df = schedules_df.withColumn(\"end_date\", to_date(col(\"end_date\"), 'yyyy-MM-dd'))\n",
    "\n",
    "# Standardize discipline, gender, and event_type\n",
    "from pyspark.sql.functions import upper, trim\n",
    "\n",
    "schedules_df = schedules_df.withColumn(\"discipline\", upper(trim(col(\"discipline\"))))\n",
    "schedules_df = schedules_df.withColumn(\"gender\", upper(trim(col(\"gender\"))))\n",
    "schedules_df = schedules_df.withColumn(\"event_type\", upper(trim(col(\"event_type\"))))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "schedules_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b19f6ded-d2eb-439e-90f7-9f0ffcc5916d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "teams = spark.read.format(\"csv\").option(\"header\",\"True\").option(\"inferSchema\",\"true\").load(\"/mnt/parisolymic/raw-data/teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23fc1d8b-5d4c-4494-88e4-6addcc602687",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----------+--------------+--------------------+------------+----------+----------------+------------+------------+-----------+\n",
      "|             code|                team|team_gender|       country|        country_full|country_code|discipline|disciplines_code|      events|num_athletes|num_coaches|\n",
      "+-----------------+--------------------+-----------+--------------+--------------------+------------+----------+----------------+------------+------------+-----------+\n",
      "|ARCMTEAM3---CHN01|People's Republic...|          M|         China|People's Republic...|         CHN|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---COL01|            Colombia|          M|      Colombia|            Colombia|         COL|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---FRA01|              France|          M|        France|              France|         FRA|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---GBR01|       Great Britain|          M| Great Britain|       Great Britain|         GBR|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---IND01|               India|          M|         India|               India|         IND|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---ITA01|               Italy|          M|         Italy|               Italy|         ITA|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---JPN01|               Japan|          M|         Japan|               Japan|         JPN|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---KAZ01|          Kazakhstan|          M|    Kazakhstan|          Kazakhstan|         KAZ|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---KOR01|   Republic of Korea|          M|         Korea|   Republic of Korea|         KOR|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---MEX01|              Mexico|          M|        Mexico|              Mexico|         MEX|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---TPE01|      Chinese Taipei|          M|Chinese Taipei|      Chinese Taipei|         TPE|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCMTEAM3---TUR01|             Trkiye|          M|       Trkiye|             Trkiye|         TUR|   Archery|             ARC|  Men's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---CHN01|People's Republic...|          W|         China|People's Republic...|         CHN|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---FRA01|              France|          W|        France|              France|         FRA|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---GBR01|       Great Britain|          W| Great Britain|       Great Britain|         GBR|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---GER01|             Germany|          W|       Germany|             Germany|         GER|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---INA01|           Indonesia|          W|     Indonesia|           Indonesia|         INA|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---IND01|               India|          W|         India|               India|         IND|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---KOR01|   Republic of Korea|          W|         Korea|   Republic of Korea|         KOR|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "|ARCWTEAM3---MAS01|            Malaysia|          W|      Malaysia|            Malaysia|         MAS|   Archery|             ARC|Women's Team|         3.0|       NULL|\n",
      "+-----------------+--------------------+-----------+--------------+--------------------+------------+----------+----------------+------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = [\n",
    "    'code', 'team', 'team_gender', 'country', 'country_full', 'country_code', \n",
    "    'discipline', 'disciplines_code', 'events', 'num_athletes', 'num_coaches'\n",
    "]\n",
    "\n",
    "# Select only the relevant columns\n",
    "teams_df = teams.select(columns_to_keep)\n",
    "\n",
    "# Drop rows with missing values in important fields\n",
    "teams_df = teams_df.dropna(subset=['team', 'country', 'discipline', 'num_athletes'])\n",
    "\n",
    "# Standardize country_code (convert to uppercase)\n",
    "from pyspark.sql.functions import upper, trim\n",
    "\n",
    "teams_df = teams_df.withColumn(\"country_code\", upper(trim(col(\"country_code\"))))\n",
    "\n",
    "# Show the cleaned DataFrame to confirm the transformations\n",
    "teams_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84894c30-03ec-481b-8610-650aa05f3ba8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "athletes_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/athletes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c3f414b-d1fc-4159-bf4b-9fb2d165720b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coaches_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/coaches\")\n",
    "events_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/events\")\n",
    "medallists_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/medallists\")\n",
    "medals_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/medals_df\")\n",
    "medals_total_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/medals_total\")\n",
    "schedules_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/schedules\")\n",
    "teams_df.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/parisolymic/transformed-data/teams\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3199950410767472,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Paris Olympic Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
